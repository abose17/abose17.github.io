---
layout: default
title: Personal Website of Avishek Bose
---
<div class="blurb">
	<h2> Projects at ORNL</h2>
	<ol>
	<li> I am working on a project called NAERM which is a sub-project of the DOE-sponsored Eagle-I initiative. My role in this project is to leverage the underlying topological structures of power stations, sub-stations, and critical infrastructure to predict their power outages during hazardous weather events by analyzing explicit and implicit correlations. </li>
    	<li> I am leading a project to transform isocontours data from various scientific visualization data sets (weather, fluid dynamics, human skull, etc.) into graph-structured data to apply GNNs to reduce the processing time of depth calculation. My implementation using GNNs performed the calculation 100 times faster than the conventional ways. </li>
    	<li> I am currently working on an NIH-sponsored drug discovery project where my task is to predict thousands of drug functionalities at a time even when there are shortages of labeled data using graph neural network (GNN), recurrent neural network (RNN), and Transformers. Another task is to predict similar drug molecules based on their properties and results in a reverse engineering fashion. </li>
        <li> I worked on \textbf{Ascend} project where my task was to enrich material knowledge graphs by providing hidden information from materials research papers, automatically using pre-trained large language models (LLMs such as GPT3 and BERT) with an attention mechanism. I also made a couple of significant analyses on BERT and GPT models according to their structural differences and usability such as why GPT models are better than BERT models, in which context BERT performs better, principles of fusing of embedding models, etc. </li>
        <li> In another material project, I used GPT and BERT embedding with GNN for predicting solid-state material properties such as bandgap, and energy formation. I achieved a noticeable performance gain over the current state of the approaches for materials property prediction.</li>
	</ol>
	<h2> Projects at K-state </h2>
	<ol>
		<li>Worked on <a href="http://www.kddresearch.org/page/82/\#gsc.tab=0">Cyber Threat Intelligence (CTI)</a> project to extract cyber-threat intelligence, classify their types, and rank threat events from social media texts such as Twitter data stream using PyTorch, scikit-learn, etc. by adopting relevant methods from GNN, NLP, and SNA research domains (\textbf{5 peer-reviewed papers accepted}, paper-1 has 94.62\% 81.99\% accuracy on CTI Relevance and Threat Type respectively, paper-2 achieves a significant precision 93.75\% for cyber threat event detection, and paper-3 outperformed baselines by 23.23\% on average for CTI relevant user detection from Twitter user network)</li>
		<li>Worked on <a href="http://www.kddresearch.org/page/70/\#gsc.tab=0">HPC Analytics</a> project to predict the status of a submitted job and its resource requirements by training Graph Neural Network (GNN) models on computing cluster log data using PyTorch (\textbf{2 peer-reviewed papers accepted}, paper-1 achieves R2 of 95\% with 99\% accuracy and paper-2 achieves a remarkable 88\% F1\_score)</li>
	</ol>
		<p>I would like to introduce myself as <em>A Learner, A Listener, and nobice ML researcher</em>. </p>
</div><!-- /.blurb -->
